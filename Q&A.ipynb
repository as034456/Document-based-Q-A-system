{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceInstructEmbeddings\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = # your unique API Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "directory='report.pdf' # upload the desired pdf file\n",
    "\n",
    "def load_docs(directory):\n",
    "    loader = PyPDFLoader(directory)\n",
    "    documents= loader.load_and_split()\n",
    "    return documents\n",
    "\n",
    "documents= load_docs(directory)\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def split_docs(documents,chunk_size=1000,chunk_overlap=20):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    docs= text_splitter.split_documents(documents)\n",
    "    return docs\n",
    "\n",
    "docs= split_docs(documents)\n",
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER 3\n",
      "RESULT AND DISCUSSION\n",
      "3.1 Resut\n",
      "As explained in the section 2.2, we used different approaches to test our data for accurate\n",
      "prediction. The accuracy thus presented is:\n",
      "Classifier Training Accuracy Testing Accuracy\n",
      "TD-if + Naive Bayes 28.72744539411206% 25.783475783475783%\n",
      "Passive Aggressive Classifier 99.82190560997329% 69.7508896797153%\n",
      "Classifier Training Accuracy Testing Accuracy\n",
      "Bigram and Tigram\n",
      "TD-if + Naive Bayes 27.326685660018995% 24.501424501424502%\n",
      "Bigram and Tigram\n",
      "Passive Aggressive Classifier 99.84416740872662% 67.88256227758008%\n",
      "3.2 Discussion\n",
      "We found that prediction based on Naive Bayes Algorithm gives poor accuracy compared\n",
      "to that of Passive Aggressive Classifier. This is because the ”naive” assumption is that\n",
      "features are independent with each other which may not be true in practice and limits its\n",
      "efficiency. In disease prediction, depending on the disease, symptoms may depend on each\n"
     ]
    }
   ],
   "source": [
    "print(docs[25].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If the decision is correct, there is no change in weight. However, it adjusts the weight\n",
      "to better classify future instances if its reading comes to be wrong. Passive Aggressive\n",
      "Classifier (PAC) works by taking a set of data and dividing it into two groups:\n",
      "1.Training Set: PAC learns how to correctly classify a data in the set.\n",
      "2.Testing Set: Once learned, PAC tests the data and the accuracy is calculated on\n",
      "the basis of that test.\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "print(docs[20].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\InstructorEmbedding\\instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n",
      "max_seq_length  512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-xl\")\n",
    "text= \"Hello World\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "len(query_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from langchain.vectorstores import Pinecone\n",
    "pinecone.init(\n",
    "    api_key= #enter your own unique api key\n",
    "    environment=#enter your own unique enviroment name\n",
    ")\n",
    "\n",
    "index_name = #\"project\"\n",
    "\n",
    "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(query, k=2, score=False):\n",
    "  if score:\n",
    "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
    "  else:\n",
    "    similar_docs = index.similarity_search(query, k=k)\n",
    "  return similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ayush\\anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "llm = HuggingFaceHub(repo_id=\"google/flan-t5-xxl\", model_kwargs={\"temperature\":0.5,\"max_length\":510450})\n",
    "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "\n",
    "def get_answer (query):\n",
    "  similar_docs = get_similar_docs(query)\n",
    "  answer = chain.run(input_documents=similar_docs, question=query)\n",
    "  return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TF-IDF( t, d, D ) = TF( t, d)IDF(t, D) 5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"what is formula for tf-idf\" # Questions from within the document\n",
    "get_answer (query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The prediction may not be accurate with the real world scenario. 2. Actual human pain/sentiment cannot be calculated to make better predictions. 3. Only the surface potential of NLP is used. 4. The data collected was not sufficient and does not have proportional distribution for large scale prediction.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the ethical effects of ML?\"\n",
    "get_answer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How far is the sun\" # Question outside the document\n",
    "get_answer(query) # Output : (I don't know)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
